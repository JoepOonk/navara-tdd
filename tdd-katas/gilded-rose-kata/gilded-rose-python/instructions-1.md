# The Gilded Rose kata

![Aged Brie](./assets/aged-brie.png)

# Introduction

Please read the general [introduction to the gilded rose kata](../README.md) first!

## Getting started

1. Create an intial Python kata set-up as described [here](https://github.com/zhendrikse/tdd/tree/master/cookiecutter):
   - Name the project/kata `gilded_rose`
   - Make sure you do _not_ select the rSpec syntax option
   - Make sure you _do_ enable the code coverage option!
3. Copy the contents of the `pyproject.toml` over the `pyproject.toml` file generated by cookiecutter.
4. Copy the contents of `gilded_rose.py` over the contents of the file in the `src` folder.
5. Copy the contents of `gilded_rose_spec.py` over the contents of the file in the `test` folder.
6. Check if everything is working by invoking the `run_tests.sh` script.

# Creating a golden master

Before we can touch/modify/refactor an existing code base, we first have to make sure we keep the current behaviour unaltered. To this extent, we first have to create a snapshot or so-called golden master.

![Snapshot](./assets/snapshot.png)

This is exactly what we will do in this excercise using [approval testing](https://approvaltests.com/).

## Inserting the approval test framework

### Step 1

The approval testing framework needs a wrapper that initializes an 
array of items containing a single item, calls the `update_quality()` function 
for that one item, and returns the updated item array (with the one item).

<details>
<summary>Wrapper that initializes an item and calls <code>update_quality()</code></summary>

```python
def do_update_quality(self, name: str, sellIn: int, quality: int) -> str:
  items = [Item(name, sellIn, quality)]
  app = GildedRose(items)
  app.update_quality()
  return app.items[0]
```
</details>

### Step 2

<details>
<summary>Wrapper that initializes an item, calls <code>update_quality()</code></summary>

This wrapper can then be used by combination approval facility of the approval testing framework, 
that needs this function as one of its parameters.

```python
def test_add_combinatorial(self):
  names = ["foo"]
  sellIns = [0]
  qualities = [0]
  verify_all_combinations(self.do_update_quality,
    [names, sellIns, qualities])
```
</details>

After running the test, the following output is generated (using the `__repr__()` function of the `Item` class).


```
args: ('foo', 0, 0) => foo, -1, 0
```

You can approve this output by promoting it to the approved text file. After that, the test should turn green!

# Improving the coverage

## Inspecting the code coverage

First we need to convert the coverage output to HTML. 
We do this by running

```bash
$ poetry run coverage html
```

in a separate shell / terminal.

Now we can inspect the code coverage by starting the
Python HTTP server:

```bash
$ python -m http.server 8000 -d htmlcov &
```

A web window should now open, displaying the code coverage. You can click on the `gilded_rose.py` file in the table.

## Getting acquainted with approval testing

Looking at the coverage report, we see that quite a lot of code is still left uncovered. Let's first improve this.

By inspection of the coverage report, we see that the "Aged Brie" if-statement on line 8 is yellow, i.e. only partically covered, so let's add "Aged Brie" to the collection of names:

```python
def test_add_combinatorial(self):
  names = ["foo", "Aged Brie"]
```

After running the test, we need to approve our base line again of course. We do this by copying the contents of the actual output to the expected output file:

```
args: ('foo', 0, 0) => foo, -1, 0
args: ('Aged Brie', 0, 0) => Aged Brie, -1, 2
```

After running the test, we see it turns green again.

Note that we can also run the suggested command in the terminal to approve the newly generated output:

```bash
$ mv -f /home/runner/GildedRosePython/GildedRoseTest.test_add_combinatorial.received.txt /home/runner/GildedRosePython/GildedRoseTest.test_add_combinatorial.approved.txt
```

### Caveat

The code coverage report is only updated after the test(s) have _successfully_ been executed, i.e. after the generated output has been _approved_. 

## Doing it yourself

1. Unfortunately line 8 with the `if`-statement is still yellow. Can you see why? Can you also extend the test set so that it becomes green?


2. In the same way, the `if`-statement on line 9 prevents the next two lines to be covered. To fix this, we need to extend the test set with quality values as well. Let's add "1" to this test set, and verify that this results in the if-statement on line 9 to be fully covered. 

3. The `if`-statement on line 10 is now at least partially covered, but still lacks an item name in the test set to make it fully covered. Make that happen now as well.

4. Likewise, the `if`-statement on line 13 needs a quality of at least 50. 

5. Similarly, the `if`-statement on line 16 needs a sell-in of at least 11.

6. The `if`-statement on line 17 is a bit trickier. By inspection of the code, we see that the quality is actually increased by one, so which other quality value do we need to add to the test set? Add this value and verify it is correct by looking at the coverage report after running the test again.

7. The only line left uncovered is line 28. When we look at line 24, we see that this doesn't come as a surprise, as we lack a sell-in date less than zero!

But... are we done now?

## Mutation testing

Coverage is not the only measure of how well you are testing your code. Mutation testing is a more stringent way of doing this, and we'll need it to assure that we have covered all edge cases.

For example, let's _temporarily_ modify the decrement in line 11 from one to two:

```python
item.quality = item.quality - 2
```

and let's run the test(s) again. We immediately see the test fails, as expected (since we modified the code and thus the behaviour changed)!

So let's restore the code to its original state. 

Next, try to do the same by increasing the increment in line 18 by one. However, the tests now stay green! This is unwanted, since we modified the behaviour. The tests should notify us in such a case!

1. Let's first revert line 18 to its original state.

2. Can you figure out which value(s) we need to add to our test set? **Hint**: we are most likely missing some intermediate value between zero and eleven for the sell-in.

3. Add the missing sell-in and verify if mutating line 18 again now results in a failing test. If not, try again!

4. Analogously, try to modify line 21. Does the test fail after mutating the code?

5. Which value would you suggest to extend the test set with? **Hint**: we are most likely missing some intermediate value between zero and six for the sell-in.

6. Revert the code to its original state and add the missing sell-in. Verify if mutating line 21 again now results in a failing test. If not, try again!

7. Verify that we also catch mutating line 23 by decrementing by two instead of one.

8. Do the same for lines 29 and 34.

9. Would you feel confident enough now to start refactoring the code? If so, why, if not, why not?
